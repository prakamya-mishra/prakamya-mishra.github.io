---
layout: post
comments: false
title: "STEPs-RL: Speech-Text Entanglement for Phonetically Sound Representation Learning"
date: 2020-11-23 00:00:00
tags: paper speech representation-learning
---

> **Abstract:** In this post, I will present a novel multi-modal deep neural network architecture that uses speech and text entanglement for learning phonetically sound spoken-word representations (STEPs-RL). STEPs-RL is trained in a supervised manner to predict the phonetic sequence of a target spoken-word using its contextual spoken word's speech and text, such that the model encodes its meaningful latent representations. Unlike existing work, I have used text along with speech for auditory representation learning to capture semantical and syntactical information along with the acoustic and temporal information.


<!--more-->

{: class="table-of-content"}
* TOC
{:toc}


<!-- ## What is language modeling?

### History

## Language models

### ELMo

### GPT

### BERT

### Transformer-XL

### Longformer

### GPT-3

## My take on future of language modeling

---

Cited as:
```
@article{prakamya2020LG,
  title   = "Language Modeling in 2020",
  author  = "Prakamya Mishra",
  journal = "prakamya-mishra.github.io/Blog",
  year    = "202020",
  url     = "https://prakamya-mishra.github.io/Blog/2020/10/27/language-models.html"
}
```

 -->

```
Posts comming soon.
```
---
layout: post
comments: false
title: "Can present AI models comprehend sarcasm properly?"
date: 2020-12-18 00:00:00
tags: review
---

> **Abstract:** In this post I comment on the capability of the present AI systems to comprehend sarcasm by investigating the present work. At the end I also reason out why the present state of AI is incapable for properly understanding sarcasm.   


<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

## Introduction

Natural language processing, popularly known as NLP deals in making computers intelligent enough to meaningfully process human language. Some common applications are document topic classification and text summarization. Sentiment analysis is another application in which the goal is to extract a person’s opinion from a piece of text written by them. In recent times, social media has become pervasive in every walk of people’s life. About 4 petabytes of data is generated every day on Facebook. A little more insight into this figure would show that roughly 4 million likes are generated every minute and close to 350 million photos are uploaded onto Facebook daily. Also, close to 1.42 billion reddit comments are generated across Reddit every month. The sheer number of people involved and their collective activity leads to a vast amount of data being shared between them regarding a wide range of topics. A lot of this information can be of value to many different stakeholders. One example from the recent past is the US elections, wherein a particular political party could gauge people’s sentiment by analyzing online activity. This generation of large amounts of data in a short time becomes too much to handle manually. Hence, social media is the perfect platform to perform any kind of sentiment analysis using NLP.

The online Oxford dictionary defines sarcasm as “the use of irony to make or convey contempt”. Merriam-Webster defines it as “a sharp and often satirical or ironic utterance designed to cut or give pain”. Sarcasm is a form of figurative language whose utterance can alter its sentiment. It is used in daily life to make jokes or at times to criticize people, ideas, or events. 

Some examples of sarcasm are:
- Oh, how I love being ignored. #sarcasm.
- Absolutely love it when my lift is late #sarcasm
- Wow, that’s a huge discount, I am not buying anything!!

This ambiguous nature of sarcasm makes it difficult even for humans at times in deciding if the nature of the remark was sarcastic or not. Sarcastic sentences usually use words that can have different meanings based on the context in which it appears (polysemy), which can be misleading for machine learning models for detecting sarcasm. Given this uniquely confusing nature of sarcasm, it becomes really difficult for NLP based applications such as review summarization and dialogue systems to identify the user’s sentiment. Thus, it is important to have in place an AI model which is able to identify sarcasm in the reviews. 

Developing truly conversational speech agents that can understand all the unique intricacies of the human language - remains one of the most important pending NLP problems of this time. Humans regularly use sarcasm as a crucial part of the day-to-day conversation when venting, arguing, or maybe engaging in humorous banter with friends. For an agent to really be conversational, detection of sarcasm may be a must. 

Understanding sarcasm, which is usually a difficult task even for humans, maybe a challenging task for machines. Common approaches for sarcasm detection are supported by machine learning classifiers trained on simple lexical or dictionary-based features. To date, some research in sarcasm detection has been done on collections of tweets from Twitter, reviews on Amazon, and comments/replies on Reddit. Reddit is an online discussion platform, where the community members can post information regarding news, politics, hobbies, etc, and any other areas of interest. The areas of interest are categorized as subreddits (/news, /politics, etc).

## The present state of AI in sarcasm detection

The main aim of this sections is to describe different works that have already happened in the field of sarcasm detection and to also give an overview of the recent advances in natural language processing for sentiment analysis. I will first start by describing the previously done work chronologically to showcase different techniques that have already been used to tackle sarcasm detection problems.

![joshi-etal-2015-harnessing]({{ '/assets/Blog/joshi-etal-2015-harnessing.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Table. 1.  Features of our sarcasm detection system. [Joshi, et al., (2015)](https://www.aclweb.org/anthology/P15-2124.pdf)*


[Joshi, Aditya, Vinita Sharma, and Pushpak Bhattacharyya. (2015)](https://www.aclweb.org/anthology/P15-2124.pdf) presented a computational system that harnesses context incongruity as a basis for sarcasm detection. They used four kinds of features: (a) Lexical, (b) Pragmatic, (c) Implicit congruity, and (d) Explicit incongruity features. Their main contribution was to introduce inter-sentential incongruity for sarcasm detection, which expanded the context of a discussion forum post by including the previous post in the discussion thread.

![amir2016modelling]({{ '/assets/Blog/amir2016modelling.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Fig. 1.  Illustration of the CUE-CNN model for sarcasm detection. The model learns to represent and exploit embeddings of both content and users in social media. [Amir, Silvio, et al. (2016)](https://www.aclweb.org/anthology/K16-1017.pdf)*

[Amir, Silvio, et al. (2016)](https://www.aclweb.org/anthology/K16-1017.pdf) proposed a model to automatically learn and then exploit user embeddings (which captured contextual features of the speaker), to be used with lexical signals to recognize sarcasm. The user embeddings required only the text from the speaker's previous posts. Their model did not require extensive manual feature engineering.

![ghosh-etal-2017-role]({{ '/assets/Blog/ghosh-etal-2017-role.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Fig. 2.  Sentence-level Attention Network for Context and Reply. [Ghosh, D., Fabbri, A. R., & Muresan, S. (2017)](https://www.aclweb.org/anthology/W17-5523.pdf)*

[Ghosh, D., Fabbri, A. R., & Muresan, S. (2017)](https://www.aclweb.org/anthology/W17-5523.pdf) mainly solved two specific problems: (1) can the conversation context be used for sarcasm detection? and (2) to realize what parts of the context were responsible for sarcasm. To deal with the primary issue, they investigate models with linguistically-motivated discrete features and several other sorts of recurrent networks (networks with sentence-level attention on context and reply) which will model both the context and therefore the sarcastic reply. To deal with the second issue, they presented an analysis of attention weights produced by the models attentively.

![ghosh-veale-2017-magnets]({{ '/assets/Blog/ghosh-veale-2017-magnets.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Fig. 3.   A Neural Architecture for Detecting Sarcasm in Contextualized Utterances. [Ghosh, Aniruddha, and Tony Veale. (2017)](https://www.aclweb.org/anthology/D17-1050.pdf)*

[Ghosh, Aniruddha, and Tony Veale. (2017)](https://www.aclweb.org/anthology/D17-1050.pdf) showed significant gains using neural architecture in sarcasm detection accuracy when knowledge of the speaker’s mood at the time of production could be inferred. They show that the mood exhibited by a speaker over tweets leading up to a new post is as useful a clue for sarcasm as the topical context of the post itself. They build a model by adding input features for the psychological profile of the author and the context of the tweet to those for the tweet itself.

[Prasad, Anukarsh G., et al. (2017) (2017)](https://ieeexplore.ieee.org/document/8169892) compare various classification algorithms such as Random Forest, Gradient Boosting, Decision Tree, Adaptive Boost, Logistic Regression, and Gaussian Naïve Bayes to detect sarcasm in tweets. The best classifier was paired with various pre-processing and filtering techniques using emoji and slang dictionary mapping to provide the best possible accuracy. Their main contribution was to use emoji and slang dictionaries for analyzing the true intentions/sentiments of the tweets.

![hazarika-etal-2018-cascade-1]({{ '/assets/Blog/hazarika-etal-2018-cascade-1.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Fig. 4.   The figure describes the process of user profiling. Stylometric and personality embeddings are generated and then fused in a multi-view setting using CCA to get the user embeddings. [Hazarika, Devamanyu, et al. (2018)](https://www.aclweb.org/anthology/C18-1156.pdf)*

![hazarika-etal-2018-cascade-2]({{ '/assets/Blog/hazarika-etal-2018-cascade-2.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Fig. 5.   Overall hybrid network of CASCADE. [Hazarika, Devamanyu, et al. (2018)](https://www.aclweb.org/anthology/C18-1156.pdf)*

[Hazarika, Devamanyu, et al. (2018)](https://www.aclweb.org/anthology/C18-1156.pdf) proposed CASCADE that utilizes a composite method of both content and context-based modeling for sarcasm detection in the online discussion forum Reddit. CASCADE uses user embeddings that encode the stylometric and character traits of the users. When used alongside content-based feature extractors like Convolutional Neural Networks (CNNs), they saw a big boost within the classification performance on an outsized Reddit corpus.

[Rajadesingan, A., Zafarani, R., & Liu, H. (2015)](https://ashwinrajadesingan.com/files/SarcasmDetection.pdf) addressed sarcasm detection on Twitter by leveraging behavioral traits intrinsic to users expressing sarcasm. They identified such traits using the user’s past tweets. They employ theories from behavioral and psychological studies to construct a behavioral modeling framework tuned for detecting sarcasm. They also identified different sorts of sarcasm and demonstrated how these forms are manifested on Twitter. They introduced behavioral modeling as a replacement, effective approach for detecting sarcasm on Twitter.

![pamungkas-patti-2018-nondicevosulserio]({{ '/assets/Blog/pamungkas-patti-2018-nondicevosulserio.png'| relative_url }})
{: style="width: 100%;" class="center"}
*Table. 2.    Feature Selection on each System. [Pamungkas, Endang Wahyu, and Viviana Patti. (2020)](https://www.aclweb.org/anthology/S18-1106.pdf)*

[Pamungkas, Endang Wahyu, and Viviana Patti. (2020)](https://www.aclweb.org/anthology/S18-1106.pdf) proposed to use various stylistic characteristics and utilized different affective means to tackle these tasks. They concentrated on two main tasks, Task A: whether a tweet was sarcastic or not? and Task B: Classifying tweets into various kinds of sarcasm. They conducted experiments using a support vector machine classifier, with a radial basis function kernel. They used architectural features and affective based features. Architectural features consisted of lexical and syntactical features that characterize Twitter data.


## Why is the present AI incapable of properly understanding sarcasm?

As mentioned above, sarcasm is complex in nature and usually it is implied and not explicit. That's why most of the present works use some kind of context to capture their implied meaning. Here is where the present AI models have reached a bottleneck because mostly all of them are focusing on local contextual features like immediate reply or comment. This narrows the vision of the present AI models. Most of the time the actual context required for detecting sarcasm in a sentence might come from recent events in the society or from some general knowledge, which might not be captured by focusing only on local immediate context.

To properly understand sarcasm, the AI models should first build a global context knowledge base. This type knowledge base can range from general information about different topics to recent events in the society, from information about the individuals involved to their inherent opinions. The problem with this is that not all of this information can be found easily and that's why this lack of information in return reduces the global context which in return reduces the ability of  present AI models to detect sarcasm. Context plays an important role for understanding sarcasm. The recent advances in natural language processing has led to introduction of new sophisticated language models. These language models have increased the ability of AI models to better understand the context by using self attention mechanisms. These language models can further increase the performance of the sarcasm detection task, but the problem with them is that they are huge in size (highly computational intensive). So at present it's impossible to increase the size of context while using these big language models, which also creates a bottleneck. Also, present attention mechanisms cannot capture contextual information properly without losing important information from longer context. These are just the problems that we face if we only use text for sarcasm detection, using higher dimensional information like images, speech and videos are beyond the scope of the present AI models. Use of these higher dimensional data leads to additional complexity of tone analysis, expression recognition, temporal change in facial features, etc. The future of sarcasm detection and modeling will depend on the ability of the AI models to capture a large quantity of high quality contextual information and better AI models and attention mechanisms that can capture long sequences of context without losing any important information.
<!--## Model
In this paper, we propose STEPs-RL: Speech-Text Entanglement for Phonetically Sound Representation Learning. STEPs-RL is a novel spoken-word representation learning approach which entangles speech and text based contextual information for learning phonetically sound spoken-word representations. The model architecture is shown in Figure 1. Given a target spoken-word, its left and right contextual spoken-words, along with the textual word embeddings of the corresponding spoken-words, the proposed model tries to learn a vector representation of the target spoken-word that not only captures the semantic-based, syntax-based and acoustic-based information but also captures the phonetic-based information. Here, a single spoken-word consists of a sequence of acoustic features Mel-frequency Cepstral Coefficients (MFCCs); Each of the spoken-word is padded with silence, so that they all consists of a sequence of \(n\) acoustic features.

![STEPs-RL Model Architecture]({{ '/assets/Blog/STEPs-RL-SpeechVec.png' | relative_url }})
{: style="width: 40%;" class="center"}
Fig. 1. Illustration of the STEPs-RL model architecture.
{: style="width: 50%;" class="center"}

Our approach uses Bidirectional-LSTM for capturing the contextual information. Bidirectional-LSTM (also known as Bi-LSTM), uses two LSTM networks to capture contextual information in opposite directions (forward and backward) of a sequence. The final hidden representations corresponding to the sequence tokens is generated by concatenating the hidden representations generated by both the LSTM networks.

STEPs-RL consist of three independent Bi-LSTM networks represented by to capture contextual information respectively from (1) The acoustic features of the left and right contextual spoken-words, (2) The acoustic features of the target spoken-word, and (3) The pre-trained textual word embeddings of the corresponding target spoken-word, left contextual spoken-words and right contextual spoken-words.

All the three Bi-LSTM networks generate a final hidden state representation corresponding to each timestamp, a final output of the corresponding forward LSTM network, and a final output of the corresponding backward LSTM network. The final forward and backward outputs of $$BiLSTM_{C}$$ & $$BiLSTM_{W}$$ are concatenated to generate $$f^C$$ & $$f^W$$ respectively, which will later act as context vectors during the entanglement of speech and text.

![STEPs-RL Phase 1]({{ '/assets/Blog/STEPs-RL-sec1.png' | relative_url }})
{: style="width: 40%;" class="center"}
Fig. 2. STEPs-RL Phase 1: Each of the individual Bi-LSTM captures contextual information.
{: style="width: 50%;" class="center"}

For intuition, $$f^C$$ represents the final contextual representation of the spoken-words present in context of the target spoken-word, and $$f^W$$ represents the final semantical and syntactical contextual representation of all the corresponding textual words. In other words, $$f^C$$ captures the acoustic/speech-based contextual information whereas $$f^W$$ captures the text-based contextual information. Both $$f^C$$ & $$f^W$$, are then used to entangle speech and text-based contextual information with the target spoken-word by generating new speech and text entangled bidirectional hidden state representations of the target spoken-word by generating attention scores using the hidden representations generated by $$BiLSTM_{T}$$.

![STEPs-RL Phase 2]({{ '/assets/Blog/STEPs-RL-sec2.png' | relative_url }})
{: style="width: 40%;" class="center"}
Fig. 3. STEPs-RL Phase 2: Speech \& Text entanglement with target spoken word.
{: style="width: 50%;" class="center"}

In the above figure, $$h^{T,C}$$ & $$h^{T,W}$$ represents the newly generated speech-entangled and text-entangled hidden representations respectively; $$\alpha_i^{T,C}$$ & $$\alpha_i^{T,W}$$ represents the speech-entangled and text-entangled attention scores respectively, corresponding to the $$i^{th}$$ timestamp of the hidden representations generated by $$BiLSTM_{T}$$. The attention scores $$\alpha_i^{T,C}$$ & $$\alpha_i^{T,W}$$ are generated by taking the dot product ($$\bullet$$) of each of the timestamps of $$h^T$$ with the context vectors $$f^C$$ & $$f^W$$ respectively.

![STEPs-RL Phase 3]({{ '/assets/Blog/STEPs-RL-sec3.png' | relative_url }})
{: style="width: 40%;" class="center"}
Fig. 4. STEPs-RL Phase 3: Latent representation learning
{: style="width: 50%;" class="center"}

Next, the proposed model uses the newly generated speech-entangled and text-entangled hidden representations, along with the original bidirectional hidden state representations of the target spoken-word, to generate a latent vector representation $$z$$ of the target spoken-word by stacking (illustrated in Figure 4) all these three hidden representations on top of each other and passing it through a simple encoder LSTM network $$\overrightarrow{LSTM_{encode}}$$.

To add more information about the speaker, the proposed model linearly combines the latent vector with an auxiliary vector to generate a new latent representation of the target spoken-word. This new latent representation is the one that the proposed model tries to learn. The auxiliary vector is a one-hot vector that consists of information related to the speaker's gender/dialect or both. Such an auxiliary vector was introduced because usually, the pronunciation of different words usually depends on the speaker's gender and dialect and hence can help learn phonetically sound spoken-word representations. 

Next, the proposed model uses a decoder LSTM network $$\overrightarrow{LSTM_{decode}}$$ to predict the sequence of phonetic symbols of the corresponding target spoken-word using the above generated latent representation of the target spoken-word $$z_{new}$$.

## Experimental Setup

## Results

## Future

-->

---

Cited as:
```
@article{prakamya2020AIsarcasm,
  title   = "SCan present AI models comprehend sarcasm properly?"",
  author  = "Prakamya Mishra",
  journal = "prakamya-mishra.github.io/Blog",
  year    = "2020",
  url     = "https://prakamya-mishra.github.io/Blog/2020-11-24-Blog-1.html"
}
```


<!-- 
---
```
Post comming soon.
``` -->
